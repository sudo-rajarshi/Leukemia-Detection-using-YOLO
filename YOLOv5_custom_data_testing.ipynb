{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /mnt/87433d53-66f3-438e-a7f4-fc990fe61283/PROJECTS/yolov5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "clear_output()\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path = '/mnt/87433d53-66f3-438e-a7f4-fc990fe61283/PROJECTS/yolov5/runs/train/exp3/weights/best.pt')  # or yolov5m, yolov5l, yolov5x, custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model('/mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/Leukomia/ALL-IDB/train/Im002_1.jpg')\n",
    "coordinates = results.xyxy[0].cpu().numpy()\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw YOLO predicted bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/Leukomia/ALL-IDB/test-from-train'\n",
    "output_dir = '/mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/Leukomia/ALL-IDB/outputs'\n",
    "\n",
    "for filename in os.listdir(test_dir):\n",
    "    file = os.path.join(test_dir, filename)\n",
    "#     img = cv2.imread(file)\n",
    "    results = model(file)\n",
    "\n",
    "    coordinates = results.xyxy[0].cpu().numpy()\n",
    "    \n",
    "    im = cv2.imread(file)\n",
    "    for i in coordinates:\n",
    "        start = (int(i[0]),int(i[1]))\n",
    "        \n",
    "        end = (int(i[2]),int(i[3]))\n",
    "        cv2.rectangle(im, start, end, (255,0,0), 2)\n",
    "\n",
    "    cv2.imwrite(os.path.join(output_dir, filename), im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "# Image\n",
    "im = 'https://ultralytics.com/images/zidane.jpg'\n",
    "\n",
    "# Inference\n",
    "results = model(im)\n",
    "\n",
    "results.pandas().xyxy[0]\n",
    "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
    "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
    "# 1  433.50  433.50   517.5  714.5    0.687988     27     tie\n",
    "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
    "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "wts_path = '/mnt/87433d53-66f3-438e-a7f4-fc990fe61283/PROJECTS/yolov5/runs/train/exp5/weights/best.pt'\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path = wts_path)\n",
    "\n",
    "for filename in os.listdir(raw_img_dir):\n",
    "    file = os.path.join(raw_img_dir, filename)\n",
    "    \n",
    "    results = model(file)\n",
    "\n",
    "    coordinates = results.xyxy[0].cpu().numpy()\n",
    "    \n",
    "    im = cv2.imread(file)\n",
    "    for i in coordinates:\n",
    "        start = (int(i[0]),int(i[1]))\n",
    "        \n",
    "        end = (int(i[2]),int(i[3]))\n",
    "        cv2.rectangle(im, start, end, (255,0,0), 2)\n",
    "\n",
    "    cv2.imwrite(os.path.join(output_dir, filename), im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .tif to .jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(output_dir):\n",
    "    if '.tif' in filename:\n",
    "        file = os.path.join(output_dir, filename)\n",
    "        print(file)\n",
    "        img = cv2.imread(file)\n",
    "        img = cv2.imwrite(os.path.join(output_dir, filename[:-3]+'jpg'), img)\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_dir = os.path.join(data_root_dir, 'Comparison')\n",
    "\n",
    "for i, j, k in zip(os.listdir(raw_img_dir), os.listdir(p_a_img_dir), os.listdir(output_dir)):\n",
    "    if i[-3:]  == 'jpg' and j[-3:]  == 'jpg' and k[-3:]  == 'jpg': \n",
    "        file1 = os.path.join(raw_img_dir, i)\n",
    "        file2 = os.path.join(p_a_img_dir, j)\n",
    "        file3 = os.path.join(output_dir, k)\n",
    "        \n",
    "        img1 = plt.imread(file1)\n",
    "        img2 = plt.imread(file2)\n",
    "        img3 = plt.imread(file3)\n",
    "        \n",
    "        plt.figure(figsize = (50,35))\n",
    "        plt.subplots_adjust(hspace=0.5, wspace=0.1)\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title('Original image', fontsize=35)\n",
    "        plt.imshow(img1)\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title('Pre-annotated image', fontsize=35)\n",
    "        plt.imshow(img2)\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title('YOLO predicted image', fontsize=35)\n",
    "        plt.imshow(img3)\n",
    "        plt.savefig(os.path.join(comparison_dir, i), bbox_inches = 'tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
